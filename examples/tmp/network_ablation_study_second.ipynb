{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9baff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib.resources import files\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from learn_embedding.approximators import *\n",
    "from learn_embedding.covariances import *\n",
    "from learn_embedding.kernels import SquaredExp\n",
    "from learn_embedding.embedding import Embedding\n",
    "from learn_embedding.dynamics import FirstGeometry, SecondGeometry, LinearField\n",
    "from learn_embedding.utils import *\n",
    "from learn_embedding.loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f239ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Khamesh\"\n",
    "data_path = files('learn_embedding').joinpath(os.path.join('data/lasahandwriting', '{}.mat'.format(dataset)))\n",
    "data = LasaHandwriting(data_path)\n",
    "train_x, train_y, test_x, test_y = data.load().process().dataset(target=\"acceleration\", split=0.2, visualize=False)\n",
    "dim = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a14dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_x = torch.from_numpy(train_x).float().to(device).requires_grad_(True)\n",
    "train_y = torch.from_numpy(train_y).float().to(device)\n",
    "test_x = torch.from_numpy(test_x).float().to(device).requires_grad_(True)\n",
    "test_y = torch.from_numpy(test_y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33331cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  1 Layers:  1 Neurons:  8 Loss:  21.651119232177734\n",
      "Iter:  2 Layers:  1 Neurons:  16 Loss:  17.58293914794922\n",
      "Iter:  3 Layers:  1 Neurons:  32 Loss:  16.7462100982666\n",
      "Iter:  4 Layers:  1 Neurons:  64 Loss:  13.019407272338867\n",
      "Iter:  5 Layers:  1 Neurons:  128 Loss:  11.882086753845215\n",
      "Iter:  6 Layers:  1 Neurons:  256 Loss:  15.2184419631958\n",
      "Iter:  7 Layers:  2 Neurons:  8 Loss:  18.795019149780273\n",
      "Iter:  8 Layers:  2 Neurons:  16 Loss:  16.872140884399414\n",
      "Iter:  9 Layers:  2 Neurons:  32 Loss:  14.610400199890137\n",
      "Iter:  10 Layers:  2 Neurons:  64 Loss:  9.251367568969727\n",
      "Iter:  11 Layers:  2 Neurons:  128 Loss:  11.222886085510254\n",
      "Iter:  12 Layers:  2 Neurons:  256 Loss:  11.86888599395752\n",
      "Iter:  13 Layers:  3 Neurons:  8 Loss:  20.00942611694336\n",
      "Iter:  14 Layers:  3 Neurons:  16 Loss:  19.82898712158203\n",
      "Iter:  15 Layers:  3 Neurons:  32 Loss:  10.82446002960205\n",
      "Iter:  16 Layers:  3 Neurons:  64 Loss:  12.035666465759277\n",
      "Iter:  17 Layers:  3 Neurons:  128 Loss:  18.141958236694336\n",
      "Iter:  18 Layers:  3 Neurons:  256 Loss:  12.664131164550781\n",
      "Iter:  19 Layers:  4 Neurons:  8 Loss:  20.301485061645508\n",
      "Iter:  20 Layers:  4 Neurons:  16 Loss:  16.865171432495117\n",
      "Iter:  21 Layers:  4 Neurons:  32 Loss:  16.152738571166992\n",
      "Iter:  22 Layers:  4 Neurons:  64 Loss:  11.462047576904297\n",
      "Iter:  23 Layers:  4 Neurons:  128 Loss:  27.518430709838867\n",
      "Iter:  24 Layers:  4 Neurons:  256 Loss:  16.061511993408203\n",
      "Iter:  25 Layers:  5 Neurons:  8 Loss:  20.4719295501709\n",
      "Iter:  26 Layers:  5 Neurons:  16 Loss:  15.994271278381348\n",
      "Iter:  27 Layers:  5 Neurons:  32 Loss:  12.956460952758789\n",
      "Iter:  28 Layers:  5 Neurons:  64 Loss:  18.432518005371094\n",
      "Iter:  29 Layers:  5 Neurons:  128 Loss:  27.45953369140625\n",
      "Iter:  30 Layers:  5 Neurons:  256 Loss:  27.497835159301758\n",
      "Iter:  31 Layers:  6 Neurons:  8 Loss:  27.48725128173828\n",
      "Iter:  32 Layers:  6 Neurons:  16 Loss:  15.705941200256348\n",
      "Iter:  33 Layers:  6 Neurons:  32 Loss:  14.968995094299316\n",
      "Iter:  34 Layers:  6 Neurons:  64 Loss:  27.509428024291992\n",
      "Iter:  35 Layers:  6 Neurons:  128 Loss:  27.534059524536133\n",
      "Iter:  36 Layers:  6 Neurons:  256 Loss:  27.467151641845703\n",
      "Iter:  37 Layers:  1 Neurons:  8 Loss:  20.74907112121582\n",
      "Iter:  38 Layers:  1 Neurons:  16 Loss:  18.861080169677734\n",
      "Iter:  39 Layers:  1 Neurons:  32 Loss:  15.796149253845215\n",
      "Iter:  40 Layers:  1 Neurons:  64 Loss:  13.741585731506348\n",
      "Iter:  41 Layers:  1 Neurons:  128 Loss:  15.278483390808105\n",
      "Iter:  42 Layers:  1 Neurons:  256 Loss:  14.072479248046875\n",
      "Iter:  43 Layers:  2 Neurons:  8 Loss:  18.893138885498047\n",
      "Iter:  44 Layers:  2 Neurons:  16 Loss:  15.030741691589355\n",
      "Iter:  45 Layers:  2 Neurons:  32 Loss:  11.277368545532227\n",
      "Iter:  46 Layers:  2 Neurons:  64 Loss:  9.665252685546875\n",
      "Iter:  47 Layers:  2 Neurons:  128 Loss:  11.082083702087402\n",
      "Iter:  48 Layers:  2 Neurons:  256 Loss:  16.771581649780273\n",
      "Iter:  49 Layers:  3 Neurons:  8 Loss:  21.739206314086914\n",
      "Iter:  50 Layers:  3 Neurons:  16 Loss:  19.222597122192383\n",
      "Iter:  51 Layers:  3 Neurons:  32 Loss:  13.646472930908203\n",
      "Iter:  52 Layers:  3 Neurons:  64 Loss:  14.11072826385498\n",
      "Iter:  53 Layers:  3 Neurons:  128 Loss:  12.79348087310791\n",
      "Iter:  54 Layers:  3 Neurons:  256 Loss:  11.652385711669922\n",
      "Iter:  55 Layers:  4 Neurons:  8 Loss:  18.567060470581055\n",
      "Iter:  56 Layers:  4 Neurons:  16 Loss:  15.12734603881836\n",
      "Iter:  57 Layers:  4 Neurons:  32 Loss:  14.52499008178711\n",
      "Iter:  58 Layers:  4 Neurons:  64 Loss:  15.421379089355469\n",
      "Iter:  59 Layers:  4 Neurons:  128 Loss:  12.822659492492676\n",
      "Iter:  60 Layers:  4 Neurons:  256 Loss:  27.589435577392578\n",
      "Iter:  61 Layers:  5 Neurons:  8 Loss:  20.251148223876953\n",
      "Iter:  62 Layers:  5 Neurons:  16 Loss:  15.305176734924316\n",
      "Iter:  63 Layers:  5 Neurons:  32 Loss:  12.724873542785645\n",
      "Iter:  64 Layers:  5 Neurons:  64 Loss:  10.632250785827637\n",
      "Iter:  65 Layers:  5 Neurons:  128 Loss:  27.4468936920166\n",
      "Iter:  66 Layers:  5 Neurons:  256 Loss:  15.499567031860352\n",
      "Iter:  67 Layers:  6 Neurons:  8 Loss:  15.820834159851074\n",
      "Iter:  68 Layers:  6 Neurons:  16 Loss:  16.637407302856445\n",
      "Iter:  69 Layers:  6 Neurons:  32 Loss:  15.361316680908203\n",
      "Iter:  70 Layers:  6 Neurons:  64 Loss:  11.715178489685059\n",
      "Iter:  71 Layers:  6 Neurons:  128 Loss:  27.568714141845703\n",
      "Iter:  72 Layers:  6 Neurons:  256 Loss:  27.478422164916992\n"
     ]
    }
   ],
   "source": [
    "attractor = torch.tensor([0.0,0.0]).to(device)\n",
    "\n",
    "reps = 2\n",
    "num_neurons = [8, 16, 32, 64, 128, 256]\n",
    "num_layers = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "counter = 1\n",
    "loss_log = torch.zeros(len(num_layers), len(num_neurons), reps)\n",
    "\n",
    "for k in range(reps):\n",
    "    for i, l in enumerate(num_layers):\n",
    "        for j, n in enumerate(num_neurons):\n",
    "#             torch.manual_seed(1337)\n",
    "            model = SecondGeometry(Embedding(FeedForward(dim, [n]*l, 1)), attractor, SPD(dim), SPD(dim)).to(device)\n",
    "\n",
    "            trainer = Trainer(model, train_x, train_y)\n",
    "        \n",
    "            trainer.optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "            # trainer.optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2, weight_decay=1e-1)\n",
    "            \n",
    "#             trainer.loss = torch.nn.MSELoss()\n",
    "            trainer.loss = torch.nn.SmoothL1Loss()\n",
    "            \n",
    "            trainer.options(normalize=False, shuffle=True, print_loss=False,epochs=2000)\n",
    "            trainer.train()\n",
    "\n",
    "            loss_log[i,j,k] = trainer.loss(model(train_x),train_y).item()\n",
    "            print(\"Iter: \", counter, \"Layers: \", l, \"Neurons: \", n, \"Loss: \", loss_log[i,j,k].item())\n",
    "            counter += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee83ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.2001, 18.2220, 16.2712, 13.3805, 13.5803, 14.6455],\n",
       "        [18.8441, 15.9514, 12.9439,  9.4583, 11.1525, 14.3202],\n",
       "        [20.8743, 19.5258, 12.2355, 13.0732, 15.4677, 12.1583],\n",
       "        [19.4343, 15.9963, 15.3389, 13.4417, 20.1705, 21.8255],\n",
       "        [20.3615, 15.6497, 12.8407, 14.5324, 27.4532, 21.4987],\n",
       "        [21.6540, 16.1717, 15.1652, 19.6123, 27.5514, 27.4728]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log.mean(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a78d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3784e-01, 9.0378e-01, 6.7179e-01, 5.1066e-01, 2.4016e+00, 8.1032e-01],\n",
       "        [6.9381e-02, 1.3021e+00, 2.3568e+00, 2.9266e-01, 9.9562e-02, 3.4667e+00],\n",
       "        [1.2231e+00, 4.2878e-01, 1.9955e+00, 1.4673e+00, 3.7819e+00, 7.1541e-01],\n",
       "        [1.2264e+00, 1.2288e+00, 1.1510e+00, 2.7997e+00, 1.0391e+01, 8.1515e+00],\n",
       "        [1.5612e-01, 4.8726e-01, 1.6376e-01, 5.5156e+00, 8.9378e-03, 8.4841e+00],\n",
       "        [8.2494e+00, 6.5865e-01, 2.7741e-01, 1.1168e+01, 2.4505e-02, 7.9695e-03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log.std(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01617c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
