{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9baff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib.resources import files\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from learn_embedding.approximators import *\n",
    "from learn_embedding.covariances import *\n",
    "from learn_embedding.kernels import SquaredExp\n",
    "from learn_embedding.embedding import Embedding\n",
    "from learn_embedding.dynamics import FirstGeometry, SecondGeometry\n",
    "from learn_embedding.utils import *\n",
    "from learn_embedding.loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f239ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "num_traj = 3  # Number of trajectories\n",
    "num_samples = 1000  # Desired number of samples per trajectory\n",
    "first_order = False\n",
    "\n",
    "train_x = np.empty((0, 2)) if first_order else np.empty((0, 4))\n",
    "train_y = np.empty((0, 2))\n",
    "\n",
    "for i in range(1, num_traj + 1):\n",
    "    # Load trajectory data\n",
    "    data = np.loadtxt(\"../learn_embedding/data/toycase/trajectory_\" + str(i) + \".csv\")\n",
    "    \n",
    "    # subsample\n",
    "    idx = DataProcess.subsample(data[:,:2], num_samples)\n",
    "    data[idx,:2] -= data[-1,:2]\n",
    "    data[-1,2:4] = np.zeros(2)\n",
    "    data[-1,-2:] = np.zeros(2)\n",
    "    \n",
    "    # add to datset\n",
    "    train_x = np.append(train_x, data[idx,:2], axis=0)  if first_order else np.append(train_x, data[idx,:4], axis=0)\n",
    "    train_y = np.append(train_y, data[idx,2:4], axis=0) if first_order else np.append(train_y, data[idx,-2:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a14dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_x = torch.from_numpy(train_x).float().to(device).requires_grad_(True)\n",
    "train_y = torch.from_numpy(train_y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33331cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  1 Layers:  1 Neurons:  8 Loss:  0.0021159122698009014\n",
      "Iter:  2 Layers:  1 Neurons:  16 Loss:  0.0005824918043799698\n",
      "Iter:  3 Layers:  1 Neurons:  32 Loss:  0.0007172435289248824\n",
      "Iter:  4 Layers:  1 Neurons:  64 Loss:  0.0009181457571685314\n",
      "Iter:  5 Layers:  1 Neurons:  128 Loss:  0.0005858172080479562\n",
      "Iter:  6 Layers:  1 Neurons:  256 Loss:  0.001829477259889245\n",
      "Iter:  7 Layers:  2 Neurons:  8 Loss:  0.0012048723874613643\n",
      "Iter:  8 Layers:  2 Neurons:  16 Loss:  0.0010371562093496323\n",
      "Iter:  9 Layers:  2 Neurons:  32 Loss:  0.0008235651184804738\n",
      "Iter:  10 Layers:  2 Neurons:  64 Loss:  0.001142196822911501\n",
      "Iter:  11 Layers:  2 Neurons:  128 Loss:  0.0009353903005830944\n",
      "Iter:  12 Layers:  2 Neurons:  256 Loss:  0.0016045888187363744\n",
      "Iter:  13 Layers:  3 Neurons:  8 Loss:  0.00028444704366847873\n",
      "Iter:  14 Layers:  3 Neurons:  16 Loss:  0.0005533546209335327\n",
      "Iter:  15 Layers:  3 Neurons:  32 Loss:  0.0008019920205697417\n",
      "Iter:  16 Layers:  3 Neurons:  64 Loss:  0.000653264403808862\n",
      "Iter:  17 Layers:  3 Neurons:  128 Loss:  0.0015577950980514288\n",
      "Iter:  18 Layers:  3 Neurons:  256 Loss:  0.0006155912997201085\n",
      "Iter:  19 Layers:  4 Neurons:  8 Loss:  0.0007911525899544358\n",
      "Iter:  20 Layers:  4 Neurons:  16 Loss:  0.0010735163232311606\n",
      "Iter:  21 Layers:  4 Neurons:  32 Loss:  0.0008503997232764959\n",
      "Iter:  22 Layers:  4 Neurons:  64 Loss:  0.0036903058644384146\n",
      "Iter:  23 Layers:  4 Neurons:  128 Loss:  0.003579795127734542\n",
      "Iter:  24 Layers:  4 Neurons:  256 Loss:  0.005261802114546299\n",
      "Iter:  25 Layers:  5 Neurons:  8 Loss:  0.00130936480127275\n",
      "Iter:  26 Layers:  5 Neurons:  16 Loss:  0.005205249413847923\n",
      "Iter:  27 Layers:  5 Neurons:  32 Loss:  0.0018739860970526934\n",
      "Iter:  28 Layers:  5 Neurons:  64 Loss:  0.0016463662032037973\n",
      "Iter:  29 Layers:  5 Neurons:  128 Loss:  0.0006969956448301673\n",
      "Iter:  30 Layers:  5 Neurons:  256 Loss:  0.0011655580019578338\n",
      "Iter:  31 Layers:  6 Neurons:  8 Loss:  0.00095037353457883\n",
      "Iter:  32 Layers:  6 Neurons:  16 Loss:  0.0017239621374756098\n",
      "Iter:  33 Layers:  6 Neurons:  32 Loss:  0.000888850016053766\n",
      "Iter:  34 Layers:  6 Neurons:  64 Loss:  0.0009027077467180789\n",
      "Iter:  35 Layers:  6 Neurons:  128 Loss:  0.003979577217251062\n",
      "Iter:  36 Layers:  6 Neurons:  256 Loss:  0.00788592454046011\n",
      "Iter:  37 Layers:  1 Neurons:  8 Loss:  0.0010821823962032795\n",
      "Iter:  38 Layers:  1 Neurons:  16 Loss:  0.0007973175379447639\n",
      "Iter:  39 Layers:  1 Neurons:  32 Loss:  0.0006944916676729918\n",
      "Iter:  40 Layers:  1 Neurons:  64 Loss:  0.0006709789740853012\n",
      "Iter:  41 Layers:  1 Neurons:  128 Loss:  0.0008493445930071175\n",
      "Iter:  42 Layers:  1 Neurons:  256 Loss:  0.001332756713964045\n",
      "Iter:  43 Layers:  2 Neurons:  8 Loss:  0.0015437266556546092\n",
      "Iter:  44 Layers:  2 Neurons:  16 Loss:  0.0007843283819966018\n",
      "Iter:  45 Layers:  2 Neurons:  32 Loss:  0.001389587763696909\n",
      "Iter:  46 Layers:  2 Neurons:  64 Loss:  0.0009392311912961304\n",
      "Iter:  47 Layers:  2 Neurons:  128 Loss:  0.0004236627137288451\n",
      "Iter:  48 Layers:  2 Neurons:  256 Loss:  0.005021371878683567\n",
      "Iter:  49 Layers:  3 Neurons:  8 Loss:  0.0005454410566017032\n",
      "Iter:  50 Layers:  3 Neurons:  16 Loss:  0.0005222174222581089\n",
      "Iter:  51 Layers:  3 Neurons:  32 Loss:  0.0006619622581638396\n",
      "Iter:  52 Layers:  3 Neurons:  64 Loss:  0.000603729858994484\n",
      "Iter:  53 Layers:  3 Neurons:  128 Loss:  0.001757852383889258\n",
      "Iter:  54 Layers:  3 Neurons:  256 Loss:  0.006163410842418671\n",
      "Iter:  55 Layers:  4 Neurons:  8 Loss:  0.001129658310674131\n",
      "Iter:  56 Layers:  4 Neurons:  16 Loss:  0.0018630294362083077\n",
      "Iter:  57 Layers:  4 Neurons:  32 Loss:  0.0014941053232178092\n",
      "Iter:  58 Layers:  4 Neurons:  64 Loss:  0.0006592056015506387\n",
      "Iter:  59 Layers:  4 Neurons:  128 Loss:  0.0074211652390658855\n",
      "Iter:  60 Layers:  4 Neurons:  256 Loss:  0.004929819609969854\n",
      "Iter:  61 Layers:  5 Neurons:  8 Loss:  0.001250942819751799\n",
      "Iter:  62 Layers:  5 Neurons:  16 Loss:  0.0008287429809570312\n",
      "Iter:  63 Layers:  5 Neurons:  32 Loss:  0.0009716897620819509\n",
      "Iter:  64 Layers:  5 Neurons:  64 Loss:  0.0012642472283914685\n",
      "Iter:  65 Layers:  5 Neurons:  128 Loss:  0.001829008455388248\n",
      "Iter:  66 Layers:  5 Neurons:  256 Loss:  0.007272785995155573\n",
      "Iter:  67 Layers:  6 Neurons:  8 Loss:  0.0007852584240026772\n",
      "Iter:  68 Layers:  6 Neurons:  16 Loss:  0.0020335610024631023\n",
      "Iter:  69 Layers:  6 Neurons:  32 Loss:  0.0004794813576154411\n",
      "Iter:  70 Layers:  6 Neurons:  64 Loss:  0.001441342057660222\n",
      "Iter:  71 Layers:  6 Neurons:  128 Loss:  0.0006682672537863255\n",
      "Iter:  72 Layers:  6 Neurons:  256 Loss:  0.005826106294989586\n",
      "Iter:  73 Layers:  1 Neurons:  8 Loss:  0.0034363404847681522\n",
      "Iter:  74 Layers:  1 Neurons:  16 Loss:  0.00098018953576684\n",
      "Iter:  75 Layers:  1 Neurons:  32 Loss:  0.0021052234806120396\n",
      "Iter:  76 Layers:  1 Neurons:  64 Loss:  0.0008142655133269727\n",
      "Iter:  77 Layers:  1 Neurons:  128 Loss:  0.0006507348152808845\n",
      "Iter:  78 Layers:  1 Neurons:  256 Loss:  0.0013964181998744607\n",
      "Iter:  79 Layers:  2 Neurons:  8 Loss:  0.0005412119207903743\n",
      "Iter:  80 Layers:  2 Neurons:  16 Loss:  0.000594837183598429\n",
      "Iter:  81 Layers:  2 Neurons:  32 Loss:  0.0005130760255269706\n",
      "Iter:  82 Layers:  2 Neurons:  64 Loss:  0.0011726856464520097\n",
      "Iter:  83 Layers:  2 Neurons:  128 Loss:  0.0026644826866686344\n",
      "Iter:  84 Layers:  2 Neurons:  256 Loss:  0.004467094782739878\n",
      "Iter:  85 Layers:  3 Neurons:  8 Loss:  0.001441256026737392\n",
      "Iter:  86 Layers:  3 Neurons:  16 Loss:  0.0010584929259493947\n",
      "Iter:  87 Layers:  3 Neurons:  32 Loss:  0.0006513181724585593\n",
      "Iter:  88 Layers:  3 Neurons:  64 Loss:  0.0003729150921572\n",
      "Iter:  89 Layers:  3 Neurons:  128 Loss:  0.0008055191137827933\n",
      "Iter:  90 Layers:  3 Neurons:  256 Loss:  0.0019586216658353806\n",
      "Iter:  91 Layers:  4 Neurons:  8 Loss:  0.0008969405316747725\n",
      "Iter:  92 Layers:  4 Neurons:  16 Loss:  0.0005238963640294969\n",
      "Iter:  93 Layers:  4 Neurons:  32 Loss:  0.0018859260017052293\n",
      "Iter:  94 Layers:  4 Neurons:  64 Loss:  0.0007057514740154147\n",
      "Iter:  95 Layers:  4 Neurons:  128 Loss:  0.004936722572892904\n",
      "Iter:  96 Layers:  4 Neurons:  256 Loss:  0.0026332088746130466\n",
      "Iter:  97 Layers:  5 Neurons:  8 Loss:  0.00053148262668401\n",
      "Iter:  98 Layers:  5 Neurons:  16 Loss:  0.002292448654770851\n",
      "Iter:  99 Layers:  5 Neurons:  32 Loss:  0.0010899680200964212\n",
      "Iter:  100 Layers:  5 Neurons:  64 Loss:  0.0015736526111140847\n",
      "Iter:  101 Layers:  5 Neurons:  128 Loss:  0.0012719871010631323\n",
      "Iter:  102 Layers:  5 Neurons:  256 Loss:  0.0062003470957279205\n",
      "Iter:  103 Layers:  6 Neurons:  8 Loss:  0.0020820542704313993\n",
      "Iter:  104 Layers:  6 Neurons:  16 Loss:  0.0017951276386156678\n",
      "Iter:  105 Layers:  6 Neurons:  32 Loss:  0.002006867900490761\n",
      "Iter:  106 Layers:  6 Neurons:  64 Loss:  0.0011834672186523676\n",
      "Iter:  107 Layers:  6 Neurons:  128 Loss:  0.005254746880382299\n",
      "Iter:  108 Layers:  6 Neurons:  256 Loss:  0.007710946723818779\n",
      "Iter:  109 Layers:  1 Neurons:  8 Loss:  0.001331094535999\n",
      "Iter:  110 Layers:  1 Neurons:  16 Loss:  0.0028192950412631035\n",
      "Iter:  111 Layers:  1 Neurons:  32 Loss:  0.0003589661791920662\n",
      "Iter:  112 Layers:  1 Neurons:  64 Loss:  0.0007256452809087932\n",
      "Iter:  113 Layers:  1 Neurons:  128 Loss:  0.0007836020668037236\n",
      "Iter:  114 Layers:  1 Neurons:  256 Loss:  0.0010071896249428391\n",
      "Iter:  115 Layers:  2 Neurons:  8 Loss:  0.0008486383012495935\n",
      "Iter:  116 Layers:  2 Neurons:  16 Loss:  0.0016340815927833319\n",
      "Iter:  117 Layers:  2 Neurons:  32 Loss:  0.0007279454148374498\n",
      "Iter:  118 Layers:  2 Neurons:  64 Loss:  0.0010852051200345159\n",
      "Iter:  119 Layers:  2 Neurons:  128 Loss:  0.0004211781488265842\n",
      "Iter:  120 Layers:  2 Neurons:  256 Loss:  0.0010423079365864396\n",
      "Iter:  121 Layers:  3 Neurons:  8 Loss:  0.0012576753506436944\n",
      "Iter:  122 Layers:  3 Neurons:  16 Loss:  0.0006221362273208797\n",
      "Iter:  123 Layers:  3 Neurons:  32 Loss:  0.0015577237354591489\n",
      "Iter:  124 Layers:  3 Neurons:  64 Loss:  0.0012314282357692719\n",
      "Iter:  125 Layers:  3 Neurons:  128 Loss:  0.0016207947628572583\n",
      "Iter:  126 Layers:  3 Neurons:  256 Loss:  0.004088310059159994\n",
      "Iter:  127 Layers:  4 Neurons:  8 Loss:  0.0013886207016184926\n",
      "Iter:  128 Layers:  4 Neurons:  16 Loss:  0.0009749232558533549\n",
      "Iter:  129 Layers:  4 Neurons:  32 Loss:  0.0013092970475554466\n",
      "Iter:  130 Layers:  4 Neurons:  64 Loss:  0.0017901357496157289\n",
      "Iter:  131 Layers:  4 Neurons:  128 Loss:  0.0007694050436839461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  132 Layers:  4 Neurons:  256 Loss:  0.0006390867056325078\n",
      "Iter:  133 Layers:  5 Neurons:  8 Loss:  0.0012595659354701638\n",
      "Iter:  134 Layers:  5 Neurons:  16 Loss:  0.0010829002130776644\n",
      "Iter:  135 Layers:  5 Neurons:  32 Loss:  0.0008401589002460241\n",
      "Iter:  136 Layers:  5 Neurons:  64 Loss:  0.0011718636378645897\n",
      "Iter:  137 Layers:  5 Neurons:  128 Loss:  0.004029595758765936\n",
      "Iter:  138 Layers:  5 Neurons:  256 Loss:  0.0038688569329679012\n",
      "Iter:  139 Layers:  6 Neurons:  8 Loss:  0.002128362189978361\n",
      "Iter:  140 Layers:  6 Neurons:  16 Loss:  0.001752906246110797\n",
      "Iter:  141 Layers:  6 Neurons:  32 Loss:  0.0014541366836056113\n",
      "Iter:  142 Layers:  6 Neurons:  64 Loss:  0.0012721836101263762\n",
      "Iter:  143 Layers:  6 Neurons:  128 Loss:  0.0011168880155310035\n",
      "Iter:  144 Layers:  6 Neurons:  256 Loss:  0.0011297912569716573\n",
      "Iter:  145 Layers:  1 Neurons:  8 Loss:  0.0005568850319832563\n",
      "Iter:  146 Layers:  1 Neurons:  16 Loss:  0.0004182429111097008\n",
      "Iter:  147 Layers:  1 Neurons:  32 Loss:  0.0012348854215815663\n",
      "Iter:  148 Layers:  1 Neurons:  64 Loss:  0.0006582193891517818\n",
      "Iter:  149 Layers:  1 Neurons:  128 Loss:  0.0015901756705716252\n",
      "Iter:  150 Layers:  1 Neurons:  256 Loss:  0.0006364205037243664\n",
      "Iter:  151 Layers:  2 Neurons:  8 Loss:  0.0007508345297537744\n",
      "Iter:  152 Layers:  2 Neurons:  16 Loss:  0.0015885536558926105\n",
      "Iter:  153 Layers:  2 Neurons:  32 Loss:  0.0005926831508986652\n",
      "Iter:  154 Layers:  2 Neurons:  64 Loss:  0.00042018454405479133\n",
      "Iter:  155 Layers:  2 Neurons:  128 Loss:  0.001221926766447723\n",
      "Iter:  156 Layers:  2 Neurons:  256 Loss:  0.0011323826620355248\n",
      "Iter:  157 Layers:  3 Neurons:  8 Loss:  0.0014224140904843807\n",
      "Iter:  158 Layers:  3 Neurons:  16 Loss:  0.0006069464143365622\n",
      "Iter:  159 Layers:  3 Neurons:  32 Loss:  0.0011367473052814603\n",
      "Iter:  160 Layers:  3 Neurons:  64 Loss:  0.0006019143620505929\n",
      "Iter:  161 Layers:  3 Neurons:  128 Loss:  0.0011774831218644977\n",
      "Iter:  162 Layers:  3 Neurons:  256 Loss:  0.0058552660048007965\n",
      "Iter:  163 Layers:  4 Neurons:  8 Loss:  0.0014791315188631415\n",
      "Iter:  164 Layers:  4 Neurons:  16 Loss:  0.0011042064288631082\n",
      "Iter:  165 Layers:  4 Neurons:  32 Loss:  0.001783480285666883\n",
      "Iter:  166 Layers:  4 Neurons:  64 Loss:  0.0006253246101550758\n",
      "Iter:  167 Layers:  4 Neurons:  128 Loss:  0.0012683132663369179\n",
      "Iter:  168 Layers:  4 Neurons:  256 Loss:  0.006834633648395538\n",
      "Iter:  169 Layers:  5 Neurons:  8 Loss:  0.0013222842244431376\n",
      "Iter:  170 Layers:  5 Neurons:  16 Loss:  0.001967361895367503\n",
      "Iter:  171 Layers:  5 Neurons:  32 Loss:  0.0019436938455328345\n",
      "Iter:  172 Layers:  5 Neurons:  64 Loss:  0.0007715107058174908\n",
      "Iter:  173 Layers:  5 Neurons:  128 Loss:  0.0007933549350127578\n",
      "Iter:  174 Layers:  5 Neurons:  256 Loss:  0.005131585989147425\n",
      "Iter:  175 Layers:  6 Neurons:  8 Loss:  0.00182620738632977\n",
      "Iter:  176 Layers:  6 Neurons:  16 Loss:  0.0012678708881139755\n",
      "Iter:  177 Layers:  6 Neurons:  32 Loss:  0.004324518609791994\n",
      "Iter:  178 Layers:  6 Neurons:  64 Loss:  0.0014851834857836366\n",
      "Iter:  179 Layers:  6 Neurons:  128 Loss:  0.0014588198391720653\n",
      "Iter:  180 Layers:  6 Neurons:  256 Loss:  0.006371567491441965\n"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "num_neurons = [8, 16, 32, 64, 128, 256]\n",
    "num_layers = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "counter = 1\n",
    "loss_log = torch.zeros(len(num_layers), len(num_neurons), reps)\n",
    "\n",
    "for k in range(reps):\n",
    "    for i, l in enumerate(num_layers):\n",
    "        for j, n in enumerate(num_neurons):\n",
    "            if first_order:\n",
    "                model = FirstGeometry(Embedding(FeedForward(dim, [n]*l, 1)), torch.tensor([0,0]).to(device), SPD(dim)).to(device)\n",
    "            else:\n",
    "                model = SecondGeometry(Embedding(FeedForward(dim, [n]*l, 1)), torch.tensor([0,0]).to(device), SPD(dim), SPD(dim)).to(device)\n",
    "                \n",
    "            trainer = Trainer(model, train_x, train_y)\n",
    "        \n",
    "            trainer.optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "            # trainer.optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2, weight_decay=1e-1)\n",
    "            \n",
    "            trainer.loss = torch.nn.MSELoss()\n",
    "            # trainer.loss = torch.nn.SmoothL1Loss()\n",
    "            \n",
    "            trainer.options(normalize=False, shuffle=True, print_loss=False,epochs=2000)\n",
    "            trainer.train()\n",
    "\n",
    "            loss_log[i,j,k] = trainer.loss(model(train_x),train_y).item()\n",
    "            print(\"Iter: \", counter, \"Layers: \", l, \"Neurons: \", n, \"Loss: \", loss_log[i,j,k].item())\n",
    "            counter += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee83ef4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7045, 1.1195, 1.0222, 0.7575, 0.8919, 1.2405],\n",
       "        [0.9779, 1.1278, 0.8094, 0.9519, 1.1333, 2.6535],\n",
       "        [0.9902, 0.6726, 0.9619, 0.6927, 1.3839, 3.7362],\n",
       "        [1.1371, 1.1079, 1.4646, 1.4941, 3.5951, 4.0597],\n",
       "        [1.1347, 2.2753, 1.3439, 1.2855, 1.7242, 4.7278],\n",
       "        [1.5545, 1.7147, 1.8308, 1.2570, 2.4957, 5.7849]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log.mean(dim=2)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003a299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(loss_log.mean(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a78d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1194, 0.9737, 0.6816, 0.1088, 0.4040, 0.4470],\n",
       "        [0.3971, 0.4687, 0.3458, 0.3105, 0.9223, 1.9304],\n",
       "        [0.5380, 0.2194, 0.3865, 0.3202, 0.3884, 2.4189],\n",
       "        [0.2990, 0.4822, 0.4127, 1.3214, 2.7312, 2.4309],\n",
       "        [0.3386, 1.7460, 0.5238, 0.3503, 1.3649, 2.3577],\n",
       "        [0.6400, 0.2781, 1.5087, 0.2330, 2.0081, 2.7450]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log.std(dim=2)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a68dae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(loss_log.std(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671798fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
